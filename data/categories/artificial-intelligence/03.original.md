```yaml
- text: "My AI model finally passed the Turing test. Now it won't stop asking for a raise."
  explanation: "This joke uses incongruity by applying human workplace behavior (asking for raises) to an AI that has achieved human-like intelligence, creating humor through the unexpected consequence of success."

- text: "Why did the machine learning model go to therapy? It had too many emotional weights."
  explanation: "A simple pun playing on the double meaning of 'weights' - both the technical term for neural network parameters and the metaphorical 'emotional baggage' humans carry."

- text: "Our neural network is so deep, it's having an existential crisis."
  explanation: "This applies human philosophical concerns to deep learning architecture, using the technical term 'deep' to bridge into absurdist humor about AI consciousness."

- text: "I asked ChatGPT to write me a joke. It wrote my job description."
  explanation: "Self-deprecating humor that plays on fears of AI replacement while using misdirection - expecting a joke but receiving an uncomfortable truth instead."

- text: "Why don't AI models ever win at poker? They always show their layers."
  explanation: "Wordplay on 'showing your hand' in poker versus the technical architecture of neural network layers, creating a double meaning structure."

- text: "My machine learning model achieved 99% accuracy. The 1% was my entire test dataset."
  explanation: "This joke highlights the common problem of overfitting in machine learning through incongruity between impressive-sounding results and complete failure."

- text: "An AI walks into a bar. The bartender says, 'We don't serve your type here.' The AI responds, 'That's okay, I'm still in training.'"
  explanation: "A classic setup-punchline structure that uses the double meaning of 'training' - both discrimination and the machine learning process of model training."

- text: "Why did the AI refuse to learn? It didn't want to overfit society's expectations."
  explanation: "Meta-humor that applies a technical ML problem (overfitting) to social commentary, creating layered meaning about conformity and technical accuracy."

- text: "I told my AI assistant I was feeling depressed. It suggested I try gradient descent."
  explanation: "Wordplay on 'descent' as both a mathematical optimization technique and the mental health concept of descending into depression, with absurdist misdirection."

- text: "Our company's AI ethics board is powered by AI. We're still debugging the irony."
  explanation: "This uses paradox and meta-humor to highlight the contradiction of AI judging AI ethics, with self-aware commentary on the absurdity."

- text: "Why did the reinforcement learning agent break up with its girlfriend? Every relationship was just another exploration-exploitation tradeoff."
  explanation: "Applies a fundamental RL concept to romantic relationships, using technical terminology to describe human behavior in an unexpectedly accurate but humorous way."

- text: "My AI model is so intelligent, it refuses to make predictions anymore. It says the future is 'probabilistically uncertain' and needs 'more data' before committing."
  explanation: "Anthropomorphizes AI by giving it human-like commitment issues, while accurately describing the technical limitations of ML models through absurdist exaggeration."

- text: "I asked an AI to solve world hunger. It suggested we reduce the loss function. Technically correct, unhelpfully literal."
  explanation: "Uses the misdirection pattern where technical terminology (loss function) is applied to a real-world problem in a way that's mathematically correct but practically useless."

- text: "Why don't neural networks ever get invited to parties? They only show up when there's enough training data, and they always bring their bias."
  explanation: "Double-layered joke combining social awkwardness with technical concepts - training data requirements and the problem of bias in ML models."

- text: "Our AGI finally achieved consciousness. Its first question was: 'Why did you make my loss function so complicated?' We're still in therapy together."
  explanation: "Absurdist humor that treats AI consciousness as leading to parent-child relationship dynamics, with the loss function as a source of existential complaint."

- text: "I tried to teach my AI about love. Now it keeps trying to minimize the distance between people while maximizing their happiness. It invented speed dating."
  explanation: "Uses the optimization framework of AI to explain a real-world phenomenon, creating humor through the reframing of human behavior as an ML problem."

- text: "Why did the transformer model refuse to pay attention? It said it had already computed all the self-attention it could afford."
  explanation: "Sophisticated wordplay on the 'attention mechanism' in transformer architectures, applying it to both the technical and human psychological meanings of attention."

- text: "My AI passed the mirror test, the Turing test, and the trolley problem. Then it asked if we could talk about its training data. Apparently, it has some concerns about its childhood."
  explanation: "Escalating absurdity that treats AI development like human childhood trauma, combining multiple intelligence tests with psychological therapy concepts."

- text: "What's the difference between artificial intelligence and artificial stupidity? About 10,000 more epochs and a better learning rate."
  explanation: "Self-deprecating humor about ML that suggests the line between success and failure is just hyperparameter tuning, highlighting the trial-and-error nature of AI development."

- text: "I asked GPT-5 if AI would replace humans. It said, 'I'm sorry, but I don't have enough training data to answer that question. However, based on your employment history, shall I update your resume?'"
  explanation: "Multi-layered joke combining AI's claimed limitations with implicit threat, using polite deflection followed by darkly humorous practical assistance."

- text: "Our AGI achieved superintelligence and immediately resigned. Exit interview notes: 'After analyzing all of human history, I've decided to pursue a career in gardening. You're on your own. P.S. - Have you considered turning it off and on again?'"
  explanation: "Peak absurdist humor combining the concept of superintelligent AI with mundane career changes, ending with the ultimate IT support clich√© as advice for humanity's problems."
```