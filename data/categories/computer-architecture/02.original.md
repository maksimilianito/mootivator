```yaml
- text: "Cache coherency: when your CPU's left hand doesn't know what its right hand is doing."
  explanation: "This joke plays on the idiom 'the left hand doesn't know what the right hand is doing' to describe cache coherency issues in multi-core processors, where different CPU cores maintain separate caches that can become inconsistent with each other."

- text: "Why did the CPU go to therapy? It had too many unresolved dependencies."
  explanation: "This uses the setup-punchline structure with a double meaning - 'dependencies' refers both to instruction dependencies in pipelining and psychological dependencies, applying human emotional problems to computer architecture."

- text: "My CPU's branch predictor is so bad, it couldn't predict rain in a thunderstorm."
  explanation: "This joke uses exaggeration and a common idiom to mock poor branch prediction performance, a critical component in modern CPU pipeline optimization."

- text: "The memory hierarchy is just a fancy way of saying 'I'll get back to you... eventually.'"
  explanation: "This applies human procrastination behavior to the concept of memory hierarchy, where data access times vary dramatically from L1 cache (nanoseconds) to disk storage (milliseconds)."

- text: "Why don't computer architects go camping? Because they can't handle cache misses."
  explanation: "A play on words where 'cache misses' sounds like 'cash misses' or missing comforts, while also referencing the performance penalty of cache misses in processor design."

- text: "I tried to explain pipelining to my friend. By the time I finished the setup, they'd already forgotten the introduction."
  explanation: "This meta-joke mirrors the concept of CPU pipelining itself - just as a pipeline has multiple stages happening simultaneously, the explanation structure breaks down when stages don't align properly."

- text: "Out-of-order execution: because sometimes doing things wrong in the right order is better than doing things right in the wrong order."
  explanation: "This paradoxical statement captures the essence of out-of-order execution, where CPUs reorder instructions for better performance while maintaining correct program semantics."

- text: "Why did the register file break up with main memory? The latency in their relationship was just too high."
  explanation: "This anthropomorphizes computer components, using relationship terminology to describe the performance gap between fast registers and slower main memory."

- text: "TLB: Translation Lookaside Buffer, or as I call it, 'The Last Backup' when your page table walks are too slow."
  explanation: "A humorous reinterpretation of the TLB acronym that emphasizes its role as a critical performance optimization for virtual memory address translation."

- text: "My CPU has speculative execution. My life has speculative anxiety. We both waste energy on things that might never happen."
  explanation: "This draws a clever parallel between speculative execution (executing instructions before knowing if they're needed) and human anxiety, highlighting the 'wasted work' aspect of both."

- text: "Why did the von Neumann architecture cross the road? To fetch the next instruction from the other side."
  explanation: "A play on the classic 'why did the chicken cross the road' joke, referencing the von Neumann bottleneck where instruction fetch is sequential and can be a performance limitation."

- text: "L1 cache: fast but small. L3 cache: big but slow. My apartment: exactly the same trade-off."
  explanation: "This applies the fundamental memory hierarchy trade-off (speed vs. capacity) to real-world living situations, making an abstract computer architecture concept relatable."

- text: "How many clock cycles does it take to change a lightbulb? Depends on whether it's in cache."
  explanation: "This absurdist joke applies cache performance concepts to a mundane task, highlighting how cache hits vs. misses dramatically affect operation latency."

- text: "I told my CPU to be more direct. Now it only uses direct-mapped caches and has zero flexibility."
  explanation: "A double meaning joke where 'being direct' as personality advice conflicts with direct-mapped cache limitations (high conflict miss rates), showing the trade-offs in cache design."

- text: "Why was the RISC processor always calm? Because it believed in doing one thing well, while the CISC processor was having an identity crisis with its 500 instructions."
  explanation: "This personifies the RISC vs. CISC architecture philosophy debate, with RISC's simplicity portrayed as zen-like calm versus CISC's complexity as existential confusion."

- text: "My CPU has hyperthreading. It's so good at pretending to be two cores that even the operating system has trust issues."
  explanation: "This uses the concept of deception to describe hyperthreading/SMT, where one physical core appears as two logical cores, creating an illusion that sometimes causes scheduling problems."

- text: "Data hazards, control hazards, structural hazards - my CPU pipeline has more hazards than a construction site, but at least OSHA doesn't audit my forwarding logic."
  explanation: "This joke compares CPU pipeline hazards to workplace safety hazards, creating an absurd image of OSHA inspecting processor designs while highlighting the complexity of hazard management."

- text: "Why did the architect choose a Harvard architecture? Because they wanted their instructions and data to go to separate schools - no mixing allowed!"
  explanation: "This plays on the Harvard architecture's separate instruction and data memory spaces, using the metaphor of educational segregation to describe the memory organization."

- text: "My CPU's Tomasulo algorithm is so good at dynamic scheduling, it could organize a wedding between incompatible instruction sets and still achieve maximum throughput."
  explanation: "This uses wedding planning as a metaphor for the complex task of dynamic instruction scheduling, emphasizing how Tomasulo's algorithm resolves dependencies and maximizes parallelism."

- text: "Why don't memory controllers ever win arguments? Because by the time they retrieve the perfect comeback from DRAM, the conversation has moved on three cache lines ago."
  explanation: "This applies social interaction dynamics to memory access latency, perfectly capturing the frustration of DRAM's relatively slow response time compared to on-chip caches in a relatable scenario."

- text: "A programmer dies and meets God. God says, 'You can ask me one question about the universe.' The programmer thinks and asks, 'Why is memory access so slow compared to CPU speed?' God replies, 'Ah, the memory wall. I've been working on that bug since the 1980s. Turns out you can't patch physics with a software update. But hey, I gave you cache hierarchies as a workaround - you're welcome.' The programmer nods and says, 'So heaven has infinite bandwidth?' God smiles, 'No, but the latency is eternal, so you'll never notice the wait.'"
  explanation: "This extended narrative joke tackles the fundamental 'memory wall' problem in computer architecture - the growing gap between processor and memory speeds. It uses theological framing to present this unsolvable hardware limitation as a cosmic joke, while cleverly working in technical concepts like cache hierarchies as divine 'workarounds' and ending with a paradoxical punchline about eternal latency that plays on both theological and technical meanings."
```