```yaml
- text: "My AI model keeps telling me it's 'learning.' I think it's just procrastinating."
  explanation: "This joke plays on the double meaning of 'learning' - both the technical process of machine learning and the common human excuse for avoiding work. It anthropomorphizes AI while highlighting the sometimes opaque nature of training processes."

- text: "Why did the neural network go to therapy? It had too many layers of issues."
  explanation: "A pun on 'layers' which are fundamental architectural components of neural networks, combined with the psychological concept of having 'layers of issues.' The joke uses technical terminology in an emotional context."

- text: "I asked my AI to be more creative. Now it hallucinates constantly."
  explanation: "This references the real problem of AI 'hallucinations' (generating false or nonsensical information) while playing on the idea that creativity and hallucination might be related, creating an incongruous comparison between desired and problematic behavior."

- text: "Machine learning is just statistics with a better PR team."
  explanation: "A meta-commentary on how machine learning is often rebranded statistics, poking fun at the hype cycle while acknowledging the marketing aspect of AI. This uses the superiority theory by deflating AI's mystique."

- text: "Why don't AI models ever finish their sentences? They keep getting interrupted by their attention mechanisms."
  explanation: "A technical joke about the attention mechanism in transformers, playing on the irony that the component designed to help models focus might actually be 'interrupting' them, anthropomorphizing the architecture."

- text: "My machine learning model achieved 99% accuracy. Unfortunately, it was predicting random numbers."
  explanation: "This highlights the importance of proper validation and the difference between high accuracy and actual usefulness, playing on the incongruity between impressive metrics and worthless results."

- text: "How do you know if someone works in AI? Don't worry, their model will tell you - it's overfitted to that information."
  explanation: "A play on the classic 'how do you know someone does X' joke format, using the technical concept of overfitting (when a model learns training data too well) to suggest the AI has memorized irrelevant personal details."

- text: "I trained a neural network to be humble. Now it keeps saying 'I'm probably wrong, but with 94.7% confidence.'"
  explanation: "The humor comes from the contradiction between humility and precise confidence scores, highlighting how AI systems quantify uncertainty in ways that seem oddly certain, creating a logical paradox."

- text: "Why did the AI researcher break up with their model? It couldn't commit - kept getting stuck in local minima."
  explanation: "A relationship metaphor using the technical concept of local minima (suboptimal solutions in optimization), where 'couldn't commit' works both romantically and technically as the model can't reach the global optimum."

- text: "Deep learning: because sometimes the best solution is to add more layers and hope for the best."
  explanation: "Self-deprecating humor about the sometimes brute-force approach in deep learning, where increasing model complexity is a common solution strategy, poking fun at the field's 'throw compute at it' mentality."

- text: "My AI assistant is so advanced, it now makes mistakes I don't understand."
  explanation: "This inverts the expectation that advanced systems should be more comprehensible, highlighting the black-box problem in AI where sophisticated models become increasingly opaque, creating humor through role reversal."

- text: "Why do AI models make terrible comedians? They keep explaining their jokes in the embedding space."
  explanation: "References the technical concept of embedding spaces (mathematical representations of data) while playing on the meta-humor of over-explaining jokes, suggesting AI lacks the social intelligence to know when to stop."

- text: "I asked GPT to write a joke about AI. It wrote a 10,000-word essay on the theoretical foundations of humor instead."
  explanation: "Meta-humor that pokes fun at large language models' tendency to be verbose and over-thorough, while also being self-referential to the very nature of AI-generated content and its sometimes excessive detail."

- text: "What's the difference between AI and a toddler? The toddler will eventually stop asking 'why' after you run out of training data."
  explanation: "Compares AI's need for training data to a child's endless questions, with the twist that children eventually mature while AI remains perpetually dependent on its dataset, highlighting AI's fundamental limitations."

- text: "My machine learning pipeline is so complex, even the bugs have dependencies."
  explanation: "Plays on the software concept of dependencies while suggesting such system complexity that even the errors are interconnected, using absurdity to comment on the reality of complicated ML workflows."

- text: "Why did the AI refuse to make predictions? It had an existential crisis during backpropagation and questioned whether gradients really exist."
  explanation: "Combines the technical process of backpropagation with philosophical existentialism, anthropomorphizing AI to create absurdist humor about whether the mathematical foundations of learning are 'real.'"

- text: "I finally understand AI: it's just matrix multiplication all the way down, with confidence."
  explanation: "A reductionist view of AI that's technically accurate but hilariously oversimplified, playing on the 'turtles all the way down' philosophical concept while highlighting how simple operations create complex behavior."

- text: "Why do data scientists love ensemble methods? Because if one model is wrong, at least you have five others to blame."
  explanation: "Ensemble methods combine multiple models for better predictions, but this joke reframes it as a blame-distribution strategy, using dark humor about accountability in ML development."

- text: "My AI model passed the Turing test. Unfortunately, it convinced everyone it was a particularly unhelpful chatbot from 2005."
  explanation: "Subverts the prestigious Turing test by suggesting the AI succeeded by imitating something terrible rather than something intelligent, using misdirection and temporal humor about old technology."

- text: "What do you call an AI that only works in production? A myth."
  explanation: "A dark joke about the notorious difficulty of deploying ML models to production environments, playing on the contrast between research success and real-world failure, using brevity for impact."

- text: "I told my neural network a joke about vanishing gradients. It didn't get it at first, but eventually the humor propagated backward through all the layers and it died laughing at the input."
  explanation: "Multi-layered technical humor about vanishing gradients (a training problem), backpropagation, and the idea of understanding traveling backward through a network, with 'died laughing' referencing gradient death while the absurdist timeline creates perfect comedic closure."
```